# 生活学习工作日记——Day5(2024.7.28)

今天是第5天，这一周4天都在加班，今天写周报写到了10点半，但是由于我不想每天到家太晚，就在家远程办公，加班时间亏了好多啊，这一周真的有些疲惫，每天的学习时间只有1个小时左右，希望后续工作上能够轻松一些，能够有充足的时间学习。不过明天终于周六了，明天早上好好睡一觉然后去公司加班，今天就继续学python多进程/多线程，这周末的话要把最近看的知识蒸馏的内容整理一下。

---

### 1. Python

```python
# 进程的两种创建方式
# fork复制主进程给子进程，所有资源的handle都让子进程继承，创建速度快但是占用内存
# spawn只会把必要的handle交给子进程，创建速度慢
---------------------------------------------------------------------

# p.join(timeout=None) 若子进程超出时间，父进程继续运行，子进程后台运行
import time
import os
from multiprocessing import Process

def run_sleep(t):
    print(f"Process start: {os.getpid()}")
    time.sleep(t)
    print("test...")
    print(f"Process {os.getpid()} end.")

if __name__ == '__main__':
    print(f"Main Process: {os.getpid()}")

    p1 = Process(target=run_sleep, args=(5,))
    p2 = Process(target=run_sleep, args=(10,))

    p1.start()
    p2.start()
    p1.join(6)
    p2.join(3)
    print("Main process end.")
# Output:
# Main Process: 15296
# Process start: 10372
# Process start: 3064
# test...
# Process 10372 end.
# Main process end.
# test...
# Process 3064 end.
# 主进程先结束，p2子进程后结束
----------------------------------------------------------

# 守护进程daemon
p2.daemon = True  # 设置p2为主进程的守护进程
# Output:
# Main Process: 21604
# Process start: 19548
# Process start: 19552
# test...
# Process 19548 end.
# Main process end.
# 主进程结束后p2进程也直接结束
-----------------------------------------------------------------

# 启动多个子进程Pool
# p.apply同步执行，程序会阻塞并等待任务完成
# p.apply_async异步执行，允许多个任务并行执行，不必等待前一个任务完成
# 使用apply
import time
import os
from multiprocessing import Process, Pool


def run_sleep(t):
    print(f"Process start: {os.getpid()}")
    time.sleep(t)
    print("test...")
    print(f"Process {os.getpid()} end.")

if __name__ == '__main__':
    p = Pool(5)
    for i in range(5):
        p.apply(run_sleep, args=(1,))
    print('Waiting all subprocess ending')
    p.close()  # 保证没有新的任务进入进程池
    p.join()
    print('All subporcesses end.')
# Output: 5个进程依次执行
'''
Process start: 22212
test...
Process 22212 end.
Process start: 22552
test...
Process 22552 end.
Process start: 16796
test...
Process 16796 end.
Process start: 3692
test...
Process 3692 end.
Process start: 9476
test...
Process 9476 end.
Waiting all subprocess ending
All subporcesses end.
'''
p.apply_async(run_sleep, args=(1,))
#Output: 5个进程一起并发
'''
Waiting all subprocess ending
Process start: 23968
Process start: 22724
Process start: 22784
Process start: 23676
Process start: 24492
test...
Process 23968 end.
test...
Process 23676 end.
test...
Process 22724 end.
test...
Process 22784 end.
test...
Process 24492 end.
All subporcesses end.
'''
# apply_async能够指定回调函数callback，任务结束后自动调用
# apply直接返回结果，apply_async返回AsyncResult对象，需要用.get函数获取结果
import time
import os
from multiprocessing import Process, Pool


def run_sleep(t):
    print(f"Process start: {os.getpid()}")
    time.sleep(t)
    print("test...")
    print(f"Process {os.getpid()} end.")
    return t * t

if __name__ == '__main__':
    p = Pool(5)
    for i in range(5):
        res = p.apply_async(run_sleep, args=(1,))
        print(res.get())
    print('Waiting all subprocess ending')
    p.close()
    p.join()
    print('All subporcesses end.')
# Output：
'''
Process start: 24172
test...
Process 24172 end.
1
Process start: 23636
test...
Process 23636 end.
1
Process start: 10728
test...
Process 10728 end.
1
Process start: 23700
test...
Process 23700 end.
1
Process start: 11380
test...
Process 11380 end.
1
Waiting all subprocess ending
All subporcesses end.
'''
# for循环将任务加入进程池执行到print需要get获取值但是get没有值造成阻塞
# 改进
res = [p.apply_async(run_sleep, args=(1,)) for _ in range(5)]
for m in res:
    print(m.get())
# Output：
'''
Process start: 24448
Process start: 23576
Process start: 23700
Process start: 21700
Process start: 21828
test...
Process 24448 end.
1
test...
Process 23576 end.
1
test...
Process 23700 end.
1
test...
Process 21828 end.
test...
Process 21700 end.
1
1
Waiting all subprocess ending
All subporcesses end.
'''
-------------------------------------------------------------------
# Python全局解释器锁GIL
# 多线程程序中，同一时刻仅有1个线程能够执行
# CPU密集型任务中，多线程由于GIL存在，可能会比单线程还慢
# I/O密集型任务，大部分处于等待状态，能够利用多线程并发

```

