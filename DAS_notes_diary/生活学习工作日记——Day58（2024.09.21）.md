# 生活学习工作日记——Day58（2024.09.21）

**日常废话：**今天周六上午休息，下午去公司上班，本来原定要开会的，结果大领导说时间冲突会议调整到周一开，早知道我就不来了。今天看同事写的技术报告，里面涉及到异常检测iforest和SOINN算法，这两个算法都了解一点点，但是没有深入地去弄清楚里面的细节，正好异常检测也是我想要熟练掌握的一个方向，今天就先不看印度佬讲红黑树了，把周志华老师的iforest的论文拿出来看一看，把里面的细节弄清楚最好自己能够动手实现一下，又给自己立flag了。。。

---

### 3. 机器学习算法

#### 1）Isolation Forest

- **背景**

  Q：之前的异常检测算法如何判断样本是否是异常？

  基于统计/分类/聚类的方法构造正常样本的轮廓(construct a profile of normal instances)，将属于该轮廓内的样本视为异常;
  会检测过多/过少异常，以及仅适合低维小数据集

  Q：IForest的特点？

  使用异常样本isolation（few and different, 异常样本更接近根节点）的概念，能够对训练数据采样建立partial model，具有线性时间复杂度，并且能够适用于不包含异常的数据集

  Q：IForest的思路？

  异常的样本一定很少，并且这些异常样本的特征的值一定会和正常样本区别很大，因此异常样本更容易被isolated；在构建一个iTree去isolate样本的时候，异常样本一定更靠近根节点，而正常样本则会分布在树的深层。IForest利用继ensemble的思想随机切分样本构建多棵itree，当某些样本在这些itree的路径较短时，这些样本就更可能是异常样本。

- **方法**

  iTree：外部节点external node(样本)，内部节点internal node（特征q，划分点p，左孩子，右孩子）

  Q：对于给定样本采样子集X={x1, x2, ..., xn}，如何构建iTree?

  递归地划分X（随机选择一个特征q和划分点p），直到：1）iTree到达了极限高度；2）X中仅有1个样本；3）X所有样本均相同；

  Path Length h(x) : 从根节点遍历到叶子节点的路径长度（BST中查找失败的路径长度）；

  Q：为什么不能够直接使用h(x)作为异常检测的评分？

  路径长度与样本数N有关，最大路径长按O(N)增长，平均路径长度按O(logN)增长，路径长度与数据集的规模有关，异常检测的评分需要规避掉数据规模的影响，在不同数据规模下也具有可比性

   Anomaly score：
  $$
  s(x, n)=2^{-\frac{E(h(x))}{c(n)}}
  $$
  E(h(x)): 所有iTree中的路径长度的均值；c(n)失败搜索的平均路径长度；该得分是将实际路径长度和BST的查找失败平均查找长度进行比较，当E(h(x))接近c(n)时，s->0.5,正常样本；E(h(x))接近0时，s->1,异常样本；

  Q：IForest为什么更适合小尺度的采样？

  当数据集很大的时候，异常点被大样本稀释，它们和正常点混杂在一起，因此使得分割的过程变得复杂，异常点和正常点的路径长度都增加，变得难以区分了。

  Q：IForest是怎么缓解异常检测的swamping(正常点与异常点过于接近导致正常点识别为异常点)和masking(异常点过多难以区分)？

  通过对数据集采样成子集，减少正常点与异常点接近的概率以及异常点过多的问题

---

- 训练

  iForest：X(train data) , t(number of trees), phy (subsample size)  --> a set of iTrees

  1. 初始化 Forest
  2. 设置树高l = ceiling(log2 phy)
  3. for i = 1 to t do:
  4. ​       采样子集X’=sample(X, phy)
  5. ​       建立iTree(X', 0, l)并添加至Forest中
  6. 返回Forest

  subsample size=256时性能最佳，增加size会增加计算资源但是性能并不会提升；number of tree=100时，路径长度更容易收敛；

  iTree：X (train data) , e (current tree height), l (height limit)  --> an iTree

  1. if e>= l (树高限制) or mod(X) <=1 (无需划分): 

  2. ​       返回外部节点exNode{size <-- mod(X)}

  3. else：

  4. ​       Q = list(X.attributes)

  5. ​        q = random.choice(Q)

  6. ​        p = random.choice([min(q), max(q)])

  7. ​        Xl = filter(X, q<=p)

  8. ​        Xr = filter(X, q>p)

  9. ​        返回内部节点inNode

     ​        其中：Left=iTree(Xl, e+1, l), Right=iTree(Xr, e+1, l), SplitAtt = q, SplitVal = p

- 推断：将样本输入每个iTree中得到h(x)，然后计算异常得分s

  PathLength h(x): x(an instance), T(an iTree), e(current path length) --> path length of x

  1. if T is exNode(到达外部节点):
  2. ​      返回 e + c(T.size)
  3. else:
  4. ​       a = T.splitAtt（找到当前节点的分裂特征）
  5. ​       if xa < T.splitVal:
  6. ​               return PathLength(x, T.Left, e+1)
  7. ​       else xa >= T.splitVal:
  8. ​               return PathLength(x, T.Right, e+1)

  Q：为什么step2返回值要加上c(T.size)？

  当 达到外部节点时如果此时并未分裂完全只是因为达到了树高，所以要补充考虑这部分未构建子树的路径长度

---

今天把这篇文章主要内容看完了，IForest的思路还是很清楚地，有空一定要自己实现一遍。先睡觉吧。